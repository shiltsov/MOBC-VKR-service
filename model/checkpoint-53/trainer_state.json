{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 53,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018867924528301886,
      "grad_norm": 31.82872200012207,
      "learning_rate": 5e-05,
      "loss": 14.2248,
      "step": 1
    },
    {
      "epoch": 0.03773584905660377,
      "grad_norm": 5.056722640991211,
      "learning_rate": 0.0001,
      "loss": 8.2002,
      "step": 2
    },
    {
      "epoch": 0.05660377358490566,
      "grad_norm": 87.14688873291016,
      "learning_rate": 0.00015,
      "loss": 8.5361,
      "step": 3
    },
    {
      "epoch": 0.07547169811320754,
      "grad_norm": 43.632144927978516,
      "learning_rate": 0.0002,
      "loss": 9.8184,
      "step": 4
    },
    {
      "epoch": 0.09433962264150944,
      "grad_norm": 10.375312805175781,
      "learning_rate": 0.00025,
      "loss": 13.0669,
      "step": 5
    },
    {
      "epoch": 0.11320754716981132,
      "grad_norm": 4.088149070739746,
      "learning_rate": 0.0003,
      "loss": 11.8838,
      "step": 6
    },
    {
      "epoch": 0.1320754716981132,
      "grad_norm": 172.22251892089844,
      "learning_rate": 0.00035,
      "loss": 10.4242,
      "step": 7
    },
    {
      "epoch": 0.1509433962264151,
      "grad_norm": 8.041447639465332,
      "learning_rate": 0.0004,
      "loss": 8.0315,
      "step": 8
    },
    {
      "epoch": 0.16981132075471697,
      "grad_norm": 13.666894912719727,
      "learning_rate": 0.00045000000000000004,
      "loss": 8.715,
      "step": 9
    },
    {
      "epoch": 0.18867924528301888,
      "grad_norm": 11.064544677734375,
      "learning_rate": 0.0005,
      "loss": 11.9003,
      "step": 10
    },
    {
      "epoch": 0.20754716981132076,
      "grad_norm": 12.546219825744629,
      "learning_rate": 0.0004998661468690914,
      "loss": 7.4734,
      "step": 11
    },
    {
      "epoch": 0.22641509433962265,
      "grad_norm": 4.081808090209961,
      "learning_rate": 0.0004994647308096509,
      "loss": 7.2727,
      "step": 12
    },
    {
      "epoch": 0.24528301886792453,
      "grad_norm": 42.40277862548828,
      "learning_rate": 0.0004987961816680492,
      "loss": 15.037,
      "step": 13
    },
    {
      "epoch": 0.2641509433962264,
      "grad_norm": 27.036876678466797,
      "learning_rate": 0.0004978612153434526,
      "loss": 10.5728,
      "step": 14
    },
    {
      "epoch": 0.2830188679245283,
      "grad_norm": 4.797910690307617,
      "learning_rate": 0.0004966608330212198,
      "loss": 6.2764,
      "step": 15
    },
    {
      "epoch": 0.3018867924528302,
      "grad_norm": 4.183885097503662,
      "learning_rate": 0.0004951963201008077,
      "loss": 6.3307,
      "step": 16
    },
    {
      "epoch": 0.32075471698113206,
      "grad_norm": 38.73165512084961,
      "learning_rate": 0.0004934692448193334,
      "loss": 6.7738,
      "step": 17
    },
    {
      "epoch": 0.33962264150943394,
      "grad_norm": 9.578958511352539,
      "learning_rate": 0.0004914814565722671,
      "loss": 5.8766,
      "step": 18
    },
    {
      "epoch": 0.3584905660377358,
      "grad_norm": 64.89820098876953,
      "learning_rate": 0.0004892350839330522,
      "loss": 8.5956,
      "step": 19
    },
    {
      "epoch": 0.37735849056603776,
      "grad_norm": 75.94768524169922,
      "learning_rate": 0.00048673253237377644,
      "loss": 6.9864,
      "step": 20
    },
    {
      "epoch": 0.39622641509433965,
      "grad_norm": 9.462235450744629,
      "learning_rate": 0.00048397648168933144,
      "loss": 4.1743,
      "step": 21
    },
    {
      "epoch": 0.41509433962264153,
      "grad_norm": 7.163152694702148,
      "learning_rate": 0.0004809698831278217,
      "loss": 3.4247,
      "step": 22
    },
    {
      "epoch": 0.4339622641509434,
      "grad_norm": 12.601997375488281,
      "learning_rate": 0.000477715956230294,
      "loss": 2.9423,
      "step": 23
    },
    {
      "epoch": 0.4528301886792453,
      "grad_norm": 18.87416648864746,
      "learning_rate": 0.0004742181853831721,
      "loss": 3.3941,
      "step": 24
    },
    {
      "epoch": 0.4716981132075472,
      "grad_norm": 7.660436630249023,
      "learning_rate": 0.00047048031608708875,
      "loss": 1.5485,
      "step": 25
    },
    {
      "epoch": 0.49056603773584906,
      "grad_norm": 3.4884655475616455,
      "learning_rate": 0.00046650635094610973,
      "loss": 1.1321,
      "step": 26
    },
    {
      "epoch": 0.5094339622641509,
      "grad_norm": 5.091476917266846,
      "learning_rate": 0.00046230054538164475,
      "loss": 1.2862,
      "step": 27
    },
    {
      "epoch": 0.5283018867924528,
      "grad_norm": 1.8368569612503052,
      "learning_rate": 0.00045786740307563633,
      "loss": 1.1993,
      "step": 28
    },
    {
      "epoch": 0.5471698113207547,
      "grad_norm": 1.2478761672973633,
      "learning_rate": 0.0004532116711479038,
      "loss": 0.895,
      "step": 29
    },
    {
      "epoch": 0.5660377358490566,
      "grad_norm": 2.394458532333374,
      "learning_rate": 0.0004483383350728088,
      "loss": 1.4123,
      "step": 30
    },
    {
      "epoch": 0.5849056603773585,
      "grad_norm": 1.9994268417358398,
      "learning_rate": 0.0004432526133406842,
      "loss": 1.15,
      "step": 31
    },
    {
      "epoch": 0.6037735849056604,
      "grad_norm": 1.8333977460861206,
      "learning_rate": 0.00043795995186974435,
      "loss": 1.1474,
      "step": 32
    },
    {
      "epoch": 0.6226415094339622,
      "grad_norm": 2.2463626861572266,
      "learning_rate": 0.0004324660181744589,
      "loss": 1.0185,
      "step": 33
    },
    {
      "epoch": 0.6415094339622641,
      "grad_norm": 4.296903610229492,
      "learning_rate": 0.00042677669529663686,
      "loss": 0.9496,
      "step": 34
    },
    {
      "epoch": 0.660377358490566,
      "grad_norm": 3.955024003982544,
      "learning_rate": 0.0004208980755057178,
      "loss": 0.9765,
      "step": 35
    },
    {
      "epoch": 0.6792452830188679,
      "grad_norm": 26.62883758544922,
      "learning_rate": 0.0004148364537750172,
      "loss": 1.6269,
      "step": 36
    },
    {
      "epoch": 0.6981132075471698,
      "grad_norm": 3.6294286251068115,
      "learning_rate": 0.0004085983210409114,
      "loss": 0.8705,
      "step": 37
    },
    {
      "epoch": 0.7169811320754716,
      "grad_norm": 2.8308253288269043,
      "learning_rate": 0.0004021903572521802,
      "loss": 0.942,
      "step": 38
    },
    {
      "epoch": 0.7358490566037735,
      "grad_norm": 3.3197314739227295,
      "learning_rate": 0.00039561942421695057,
      "loss": 0.9459,
      "step": 39
    },
    {
      "epoch": 0.7547169811320755,
      "grad_norm": 0.9447576999664307,
      "learning_rate": 0.00038889255825490053,
      "loss": 0.8632,
      "step": 40
    },
    {
      "epoch": 0.7735849056603774,
      "grad_norm": 1.076642632484436,
      "learning_rate": 0.000382016962662592,
      "loss": 0.6614,
      "step": 41
    },
    {
      "epoch": 0.7924528301886793,
      "grad_norm": 0.7594099044799805,
      "learning_rate": 0.000375,
      "loss": 0.6591,
      "step": 42
    },
    {
      "epoch": 0.8113207547169812,
      "grad_norm": 0.8193876147270203,
      "learning_rate": 0.0003678491842064995,
      "loss": 0.8782,
      "step": 43
    },
    {
      "epoch": 0.8301886792452831,
      "grad_norm": 0.9482760429382324,
      "learning_rate": 0.00036057217255475036,
      "loss": 0.7568,
      "step": 44
    },
    {
      "epoch": 0.8490566037735849,
      "grad_norm": 1.0346713066101074,
      "learning_rate": 0.00035317675745109866,
      "loss": 0.6125,
      "step": 45
    },
    {
      "epoch": 0.8679245283018868,
      "grad_norm": 1.4674056768417358,
      "learning_rate": 0.0003456708580912725,
      "loss": 0.6433,
      "step": 46
    },
    {
      "epoch": 0.8867924528301887,
      "grad_norm": 0.6369452476501465,
      "learning_rate": 0.0003380625119803084,
      "loss": 0.526,
      "step": 47
    },
    {
      "epoch": 0.9056603773584906,
      "grad_norm": 1.3893002271652222,
      "learning_rate": 0.0003303598663257904,
      "loss": 0.4955,
      "step": 48
    },
    {
      "epoch": 0.9245283018867925,
      "grad_norm": 1.6530897617340088,
      "learning_rate": 0.00032257116931361555,
      "loss": 0.5762,
      "step": 49
    },
    {
      "epoch": 0.9433962264150944,
      "grad_norm": 1.8203269243240356,
      "learning_rate": 0.00031470476127563017,
      "loss": 0.6193,
      "step": 50
    },
    {
      "epoch": 0.9622641509433962,
      "grad_norm": 0.9671713709831238,
      "learning_rate": 0.0003067690657585933,
      "loss": 0.7101,
      "step": 51
    },
    {
      "epoch": 0.9811320754716981,
      "grad_norm": 4.952826499938965,
      "learning_rate": 0.0002987725805040321,
      "loss": 0.7531,
      "step": 52
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.4475133419036865,
      "learning_rate": 0.0002907238683486472,
      "loss": 0.4253,
      "step": 53
    }
  ],
  "logging_steps": 1,
  "max_steps": 106,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 213250254336000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
